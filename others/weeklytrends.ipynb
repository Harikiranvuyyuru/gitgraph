{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import sys\n",
      "\n",
      "os.environ['PYSPARK_SUBMIT_ARGS']='--master spark://ip-172-31-0-189:7077 --executor-memory 10240m --driver-memory 10240m'\n",
      " \n",
      "spark_home = os.environ.get('SPARK_HOME', None)\n",
      "if not spark_home:\n",
      "  raise ValueError('SPARK_HOME environment variable is not set')\n",
      "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
      "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.8.2.1-src.zip'))\n",
      "execfile(os.path.join(spark_home, 'python/pyspark/shell.py'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Welcome to\n",
        "      ____              __\n",
        "     / __/__  ___ _____/ /__\n",
        "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
        "   /__ / .__/\\_,_/_/ /_/\\_\\   version 1.3.1\n",
        "      /_/\n",
        "\n",
        "Using Python version 2.7.6 (default, Mar 22 2014 22:59:56)\n",
        "SparkContext available as sc, HiveContext available as sqlContext.\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyspark import SparkContext\n",
      "from pyspark.sql import SQLContext"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sc.stop()\n",
      "sc = SparkContext(\"spark://ip-172-31-0-189:7077\", \"following\")\n",
      "sqlContext = SQLContext(sc)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = sqlContext.jsonFile(\"hdfs://ec2-52-8-127-252.us-west-1.compute.amazonaws.com:9000/weekly_trends/\")\n",
      "df_watch = df.filter('type=\"WatchEvent\"')\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}