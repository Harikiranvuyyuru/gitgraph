#!/usr/bin/env python

from bs4 import BeautifulSoup
import pickle
import urllib
import mechanize
import json

br = mechanize.Browser()
br.set_handle_robots(False)

usernames_file = open("usernames","rb")
usernames = pickle.load(usernames_file)
usernames_file.close()
#usernames = ["ronaknnathani","igrigorik"]
followers_url = "https://github.com/"
f = open("2015-01-01-0_followers.json","wb")
output = []

def get_followers(url_tail, user, followers, page):
  print len(followers)
  response = urllib.urlopen(followers_url + user + "/followers" + url_tail)
  soup = BeautifulSoup(response)
  followers_html = soup.find_all("h3", class_="follow-list-name")
  if followers_html == []:
    return followers
  else:
    for follower in followers_html:
      followers.append(str(follower.a["href"]))
    page +=1
    get_followers("?page="+str(page), user, followers, page)
    return followers

for user in usernames:
  followers = []
  followers_dict = {}
  print "\nfor user: " + user
  followers = get_followers("", user, [], 1)
  print "total followers: ", len(followers)
  followers_dict["login"] = user
  followers_dict["following"] = followers
  output.append(followers_dict)

json.dump(output, f)
